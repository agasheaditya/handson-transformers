# Hands-on Transformers
**End-to-end implementation of Transformers using PyTorch from scratch**

---

Implementing end to end Transformer model using PyTorch from scratch, and training it to generate paragraphs if given a keyword or phrase as a input. 

### Files and usage:
  - **TransformerModel.py** --> Model class containing all logic and architecture of Transformer model
  - **train_beta.ipynb** --> Jupyter Notebook to train and do the sample inference on trained model
  - **trained-transformer_model.pth** --> Trained model checkpoint _(saved state dict)_
  - **Articles.xlsx** --> Dataset used to train the model (https://www.kaggle.com/datasets/asad1m9a9h6mood/news-articles)
  - **requirements.txt** --> pip freeze of dependencies 
--- 

### Setup and Usage: 

- Environment setup
- Dependencies installation

---

### Dashboard:
Dashboard which can generate the paragrph using the trained model if given a keyword or phrase as a input. 
